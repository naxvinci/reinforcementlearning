{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.2.랜덤환경에서 Frozen Lake -2 Exploration.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkBwbBaldx0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random as pr\n",
        "from gym.envs.registration import register"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OLkX3jgq2Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#강화 학습 환경을 설정\n",
        "register(\n",
        "    id=\"FrozenLake-v1\",  #강화 학습 환경의 아이디를 설정\n",
        "    #gym.envs.toy_text:FrozenLakeEnv : FrozenLake 환경을 설정해서 리턴 하도록 설정\n",
        "    entry_point=\"gym.envs.toy_text:FrozenLakeEnv\", \n",
        "    kwargs={\n",
        "            \"map_name\": \"4x4\",  #FrozenLake 의 줄 칸을 설정 4줄 X4 칸\n",
        "            \"is_slippery\":True #미끄러짐 효과 설정 안함\n",
        "            }\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXMPER5qeAtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gym.make(\"FrozenLake-v1\"): FrozenLake-v1 환경을 설정해서 env에 리턴\n",
        "env=gym.make(\"FrozenLake-v1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZiS3AdfoiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#env.render(): Frozen Lake 게임을 출력\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahKZ-3rIYuyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#env.reset() : 현재 위지를 s 시장 위치로 설정하고 현재 위치를 리턴\n",
        "#              시작 위치는 첫번째줄 첫번째 칸이므로 0 이 리턴\n",
        "position=env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44YWW7noYzR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "position"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia1W8_dzb2Ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.zeros(): 0으로 초기화된 배열을 생성\n",
        "#np.zeros([16(줄),4(칸)]) : 0으로 초기화된 16줄 4칸의 배열을 생성\n",
        "Q=np.zeros([16,4])\n",
        "Q\n",
        "#Q[0, :] : Q배열의 0번째줄 모든 칸\n",
        "#np.amax(Q[0, :]) :Q배열의 0번째줄 모든 칸에서 최대값 리턴 1\n",
        "m=np.amax(Q[0, :])\n",
        "print(\"m:\",m)\n",
        "#np.argmax(Q[0, :]): Q배열의 0번째줄 모든 칸에서 최대값이 저장된 인덱스 리턴 2\n",
        "action=np.argmax(Q[0, :])\n",
        "print(\"action:\",action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Edt3vkzcPyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pr.choice([0,1,2,3]) : 0,1,2,3 중에서 하나의 수를 랜덤하게 선택해서 리턴\n",
        "action=pr.choice([0,1,2,3])\n",
        "print(\"action:\",action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAumxBTVY3Dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q 학습하기\n",
        "weight=0.99\n",
        "learning_rate=0.85\n",
        "# Goal에 도달 여부를 저장할 리스트\n",
        "successList = []\n",
        "\n",
        "for index in range(2000):\n",
        "    print(\"=\"*100)\n",
        "    print(\"index:\",index)\n",
        "    position = env.reset() \n",
        "    \n",
        "    # 게임의 reward를 저장할 배열, reward는 0이고 goal에 도달 했을 때만\n",
        "    totalReward = 0\n",
        "    while True:\n",
        "        #env.render(): Frozen Lake 게임을 출력\n",
        "        env.render()\n",
        "        print()\n",
        "        rand_arr = np.random.randn(1, 4) # 난수의 범위는 1 미만, 4개를 생성\n",
        "        print(\"rand_arr: \", rand_arr)\n",
        "\n",
        "        noise = rand_arr / ( index+1 ) # 인덱스가 1인 경우 2로 나눠주는게 되겠졍\n",
        "        print(\"noise: \", noise) # 진행 할수록 noise는 점점 작아지게 할겁니다\n",
        "        print(\"Q[position, :]: \", Q[position, :])\n",
        "        print(\"Q[position, :] + noise: \", Q[position, :] + noise)\n",
        "\n",
        "        action = np.argmax(Q[position, :] + noise)\n",
        "\n",
        "        print(\"action: \", action)\n",
        "        new_position, reward,done,info = env.step(action)\n",
        "        totalReward += reward\n",
        "        print(\"totalReward:\",totalReward,\"new_position:\",new_position,\":reward:\",reward,\":done:\",done,\":info:\",info)\n",
        "        \n",
        "        #(1-learning_rate)*Q[position, action]: 기존 데이터는 1-learning_rate만큼 반영\n",
        "        #learning_rate*(reward+weight*np.max(Q[position, :])):\n",
        "        #action을 취했을 때 예상되는 데이터는 learning_rate만큼 반영\n",
        "        Q[position, action]=(1-learning_rate)*Q[position, action]\\\n",
        "                    + learning_rate*(reward+weight*np.max(Q[new_position, : ]))\n",
        "\n",
        "        #new_position을 position에 대입\n",
        "        position=new_position\n",
        "        #done : 게임 종료 여부를 저장 할 변수 \n",
        "        #       True : 게임 종료\n",
        "        #       False : 게임 계속 진행\n",
        "        if done==True:\n",
        "            break;\n",
        "\n",
        "    successList.append([index, totalReward])\n",
        "\n",
        "    print(\"Q:\",Q)\n",
        "    print(\"=\"*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyObY6RtIrVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwu5pb2pOQqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "successList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3786QVzOuMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultList=list(zip(*successList)) # 리스트 안에 저장된 데이터 리턴 열방향 순으로\n",
        "resultList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDTMK1BrPK9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(list(resultList)[1]) # 성공한 횟수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRWSrEJbsPoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습이 끝났으므로 길을 잘 찾아감\n",
        "\n",
        "position = env.reset()\n",
        "\n",
        "while True:\n",
        "    #env.render(): Frozen Lake 게임을 출력\n",
        "    env.render()\n",
        "    print()\n",
        "    action=np.argmax(Q[position, :])\n",
        "    \n",
        "    new_position, reward,done,info = env.step(action)\n",
        "    #reward+np.max(Q[new_position, :]): 현재 reward+Q배열의 position 번째줄 모든 칸에서 최대값 (np.max(Q[new_position, :]) )\n",
        "    #을 Q[position,action] 에 대입\n",
        "\n",
        "    #new_position을 position에 대입\n",
        "    position=new_position\n",
        "    #done : 게임 종료 여부를 저장 할 변수 \n",
        "    #       True : 게임 종료\n",
        "    #       False : 게임 계속 진행\n",
        "    if done==True:\n",
        "        break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XooU6hrjZ4Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#sum(resultList[1]) : resultList[1] (Reward의 합 - 성공 여부가 저장되어 있음) 의 합\n",
        "#(성공여부의 전체합 즉 2000번 수행하는데 몇번 성공했는지 합) / 2000\n",
        "#성공률 계산\n",
        "print(\"성공률: \", str(sum(resultList[1]) / len(resultList[1] )))\n",
        "\n",
        "\n",
        "plt.bar(range(len(resultList[1])), resultList[1], color=\"blue\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzpC4kWf9Qzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}